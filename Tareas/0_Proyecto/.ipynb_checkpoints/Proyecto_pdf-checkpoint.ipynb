{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "63703807-0954-4c07-bf30-fde1dcda08fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#pip install pytesseract\n",
    "#pip install PyPDF2\n",
    "#pip install pdfplumber\n",
    "#pip install ocrmypdf\n",
    "#pip install PyMuPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e5f9eb-2316-4341-8c5a-5bdd5fe84f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#para trabajar con ocrmypdf se debe intalar adicionalmente: Ghostscript y Tesseract OCR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6964a65-97ae-4917-a379-3ec80d1e315d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import PyPDF2\n",
    "#import ocrmypdf\n",
    "import cv2\n",
    "import pytesseract\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a18928-5e38-40bb-8043-d774e8e14b50",
   "metadata": {},
   "source": [
    "### pasar pdf a imagen y recortarla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8348356-8fbf-46f5-a284-433d11357860",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se ha convertido la página 1 en una imagen y se ha guardado en C:\\Users\\pc\\OneDrive\\Escritorio\\OC_pdf\\Nueva carpeta\\pagina_1.png.\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Ruta del archivo PDF de entrada\n",
    "pdf_path = \"C:\\\\Users\\\\pc\\\\OneDrive\\\\Escritorio\\\\OC_pdf\\\\SEGURO EXEQUIAL Vallejo Arango Juliana.pdf\"\n",
    "\n",
    "# Directorio donde se guardarán las imágenes\n",
    "output_directory = \"C:\\\\Users\\\\pc\\\\OneDrive\\\\Escritorio\\\\OC_pdf\\\\Nueva carpeta\\\\\"\n",
    "\n",
    "# Número de página que deseas convertir (página 0 es la primera página)\n",
    "page_number = 0\n",
    "\n",
    "# Abre el archivo PDF\n",
    "pdf_document = fitz.open(pdf_path)\n",
    "\n",
    "# Asegúrate de que la carpeta de salida exista, o créala si no existe\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Selecciona la página\n",
    "page = pdf_document.load_page(page_number)\n",
    "\n",
    "# Renderiza la página como una imagen (puedes ajustar la resolución)\n",
    "pix = page.get_pixmap(matrix=fitz.Matrix(300/72, 300/72))\n",
    "\n",
    "# Construye la ruta completa para guardar la imagen\n",
    "image_path = os.path.join(output_directory, f\"pagina_{page_number + 1}.png\")\n",
    "\n",
    "# Guarda la imagen como un archivo PNG en la ruta especificada\n",
    "pix.save(image_path)\n",
    "\n",
    "# Cierra el documento PDF\n",
    "pdf_document.close()\n",
    "\n",
    "print(f\"Se ha convertido la página {page_number + 1} en una imagen y se ha guardado en {image_path}.\")\n",
    "\n",
    "# Carga la imagen convertida\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Convierte la imagen a escala de grises\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Aplica la detección de bordes (Canny)\n",
    "edges = cv2.Canny(gray, 50, 150, apertureSize=3)\n",
    "\n",
    "# Aplica la transformada de Hough para detectar líneas\n",
    "lines = cv2.HoughLinesP(edges, 1, np.pi / 180, threshold=100, minLineLength=100, maxLineGap=10)\n",
    "\n",
    "# Encuentra los puntos extremos de las líneas detectadas y recorta la imagen\n",
    "if lines is not None:\n",
    "    # Inicializa una máscara en escala de grises del mismo tamaño que la original\n",
    "    mask = np.zeros(gray.shape, dtype=np.uint8)\n",
    "\n",
    "    for line in lines:\n",
    "        x1, y1, x2, y2 = line[0]\n",
    "        \n",
    "        # Dibuja la línea en la máscara (blanco)\n",
    "        cv2.line(mask, (x1, y1), (x2, y2), 255, 2)\n",
    "\n",
    "    # Encuentra los contornos en la máscara\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if contours:\n",
    "        largest_contour = max(contours, key=cv2.contourArea)\n",
    "        x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "\n",
    "        # Recorta la región del rectángulo en la imagen original\n",
    "        imagen_recortada = image[y:y + h, x:x + w]\n",
    "\n",
    "        # Redimensiona la imagen recortada al tamaño deseado (por ejemplo, 1629x1236 píxeles)\n",
    "        nuevo_ancho = 1629\n",
    "        nuevo_alto = 1236\n",
    "        imagen_recortada = cv2.resize(imagen_recortada, (nuevo_ancho, nuevo_alto))\n",
    "\n",
    "        # Aplica un filtro de mejora de nitidez a la imagen\n",
    "        imagen_mejorada = cv2.filter2D(imagen_recortada, -1, np.array([[-1, -1, -1],\n",
    "                                                                     [-1,  9, -1],\n",
    "                                                                     [-1, -1, -1]]))\n",
    "\n",
    "        # Ruta y nombre de la imagen recortada y mejorada\n",
    "        nombre_imagen_recortada = os.path.join(output_directory, f\"pagina_{page_number + 1}.png\")\n",
    "        nombre_imagen_mejorada = os.path.join(output_directory, f\"pagina_{page_number + 1}.png\")\n",
    "\n",
    "        # Guarda la imagen recortada y la imagen mejorada en las rutas especificadas\n",
    "        #cv2.imwrite(nombre_imagen_recortada, imagen_recortada)\n",
    "        cv2.imwrite(nombre_imagen_mejorada, imagen_mejorada)\n",
    "\n",
    "        #cv2.imshow(\"Imagen Recortada\", imagen_recortada)\n",
    "        cv2.imshow(\"Imagen Mejorada\", imagen_mejorada)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "    else:\n",
    "        print(\"No se encontraron contornos en la máscara\")\n",
    "else:\n",
    "    print(\"No se encontraron líneas en la imagen\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e08dfadf-6987-4644-b762-a12b525b3261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coordenadas: (748, 119)\n",
      "Coordenadas: (1116, 246)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Carga la imagen\n",
    "image = cv2.imread(\"C:\\\\Users\\\\pc\\\\OneDrive\\\\Escritorio\\\\OC_pdf\\\\Nueva carpeta\\\\pagina_1.png\")\n",
    "\n",
    "# Crea una ventana\n",
    "cv2.namedWindow('Imagen', cv2.WINDOW_NORMAL)  # Puedes ajustar el tamaño de la ventana si lo deseas\n",
    "\n",
    "# Muestra la imagen en la ventana\n",
    "cv2.imshow('Imagen', image)\n",
    "\n",
    "# Función para manejar los clics del mouse\n",
    "def obtener_coordenadas(event, x, y, flags, param):\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        print(f'Coordenadas: ({x}, {y})')\n",
    "\n",
    "# Asigna la función de manejo de clics al evento del mouse\n",
    "cv2.setMouseCallback('Imagen', obtener_coordenadas)\n",
    "\n",
    "# Espera a que el usuario haga clic en la imagen\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Cierra la ventana\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b22155db-d37f-48bb-ad52-571aa24a3c6f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Robin Pane Reco \\\\Lh Wises\\n\\n', 'B pt [i982\\n', 'TH2 FS 44\\n', 'PADRE\\n', 'Lites Fiyel: ale is ls\\n', '1@ [12 lis\\n', 'Q2 124554\\n', 'MADRE\\n']\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "\n",
    "idioma = 'spa'\n",
    "configuracion_avanzada = '--psm 6' \n",
    "extracted_text = pytesseract.image_to_string(gray_image, lang=idioma, config=configuracion_avanzada)\n",
    "\n",
    "modelo_lenguaje = 'ruta_al_modelo' # Ruta al modelo de lenguaje específico\n",
    "\n",
    "# Carga la imagen\n",
    "image = cv2.imread(\"C:\\\\Users\\\\pc\\\\OneDrive\\\\Escritorio\\\\OC_pdf\\\\Nueva carpeta\\\\pagina_1.png\")\n",
    "\n",
    "# Define las coordenadas de las regiones de la imagen que deseas extraer\n",
    "regiones = [\n",
    "    {\"left_x\": 5, \"top_y\": 126, \"right_x\": 747, \"bottom_y\": 238},\n",
    "    {\"left_x\": 749, \"top_y\": 139, \"right_x\": 1114, \"bottom_y\": 248},\n",
    "    {\"left_x\": 1115, \"top_y\": 129, \"right_x\": 1505, \"bottom_y\": 239},\n",
    "    {\"left_x\": 1507, \"top_y\": 138, \"right_x\": 1623, \"bottom_y\": 245},\n",
    "    \n",
    "    {\"left_x\": 5, \"top_y\": 226, \"right_x\": 747, \"bottom_y\": 338},\n",
    "    {\"left_x\": 749, \"top_y\": 239, \"right_x\": 1115, \"bottom_y\": 349},\n",
    "    {\"left_x\": 1116, \"top_y\": 239, \"right_x\": 1504, \"bottom_y\": 351},\n",
    "    {\"left_x\": 1507, \"top_y\": 243, \"right_x\": 1623, \"bottom_y\": 353},\n",
    "]\n",
    "\n",
    "\n",
    "# Itera a través de las regiones y extrae el texto de cada una\n",
    "Beneficiarios =[]\n",
    "for idx, region in enumerate(regiones):\n",
    "    left_x = region[\"left_x\"]\n",
    "    top_y = region[\"top_y\"]\n",
    "    right_x = region[\"right_x\"]\n",
    "    bottom_y = region[\"bottom_y\"]\n",
    "\n",
    "    # Recorta la región de la imagen según las coordenadas\n",
    "    cropped_image = image[top_y:bottom_y, left_x:right_x]\n",
    "\n",
    "    # Convierte la imagen recortada a escala de grises\n",
    "    gray_image = cv2.cvtColor(cropped_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Extrae el texto de la imagen recortada\n",
    "    extracted_text = pytesseract.image_to_string(gray_image)\n",
    "\n",
    "    # Imprime el texto extraído o guárdalo en un archivo, según tus necesidades\n",
    "    #print(f\"Texto extraído de región {idx + 1}:\")\n",
    "\n",
    "    Beneficiarios.append(extracted_text)\n",
    "    \n",
    "print(Beneficiarios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0f87b95-38fa-438f-97fb-7be9ba66bc08",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nombre</th>\n",
       "      <th>Fecha_Nacimiento</th>\n",
       "      <th>Documento_id</th>\n",
       "      <th>Parentesco</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Robin Pane Reco \\Lh Wises\\n\\n</td>\n",
       "      <td>B pt [i982\\n</td>\n",
       "      <td>TH2 FS 44\\n</td>\n",
       "      <td>PADRE\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lites Fiyel: ale is ls\\n</td>\n",
       "      <td>1@ [12 lis\\n</td>\n",
       "      <td>Q2 124554\\n</td>\n",
       "      <td>MADRE\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Nombre Fecha_Nacimiento Documento_id Parentesco\n",
       "0  Robin Pane Reco \\Lh Wises\\n\\n     B pt [i982\\n  TH2 FS 44\\n    PADRE\\n\n",
       "1       Lites Fiyel: ale is ls\\n     1@ [12 lis\\n  Q2 124554\\n    MADRE\\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if (len(Beneficiarios)%4==0):\n",
    "    \n",
    "    chunks = [Beneficiarios[i:i+4] for i in range(0, len(Beneficiarios), 4)]\n",
    "    df = pd.DataFrame(chunks, columns=['Nombre', 'Fecha_Nacimiento', 'Documento_id', 'Parentesco'])\n",
    "else:\n",
    "    print(\"dimención incompleta\")\n",
    "    \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "05549d27-89c1-434a-b9f4-81ac16a494c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nombre</th>\n",
       "      <th>Fecha_Nacimiento</th>\n",
       "      <th>Documento_id</th>\n",
       "      <th>Parentesco</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Angelica Vannessa Ramirez Rubio\\n\\n</td>\n",
       "      <td>1992-12-11</td>\n",
       "      <td>1072667399\\n</td>\n",
       "      <td>ESPOS@\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>German Reina Bojaca\\n</td>\n",
       "      <td>1959-03-11</td>\n",
       "      <td>2994376\\n</td>\n",
       "      <td>SUEGR@\\nO PADRE\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Nombre Fecha_Nacimiento  Documento_id  \\\n",
       "0  Angelica Vannessa Ramirez Rubio\\n\\n       1992-12-11  1072667399\\n   \n",
       "1                German Reina Bojaca\\n       1959-03-11     2994376\\n   \n",
       "\n",
       "          Parentesco  \n",
       "0           ESPOS@\\n  \n",
       "1  SUEGR@\\nO PADRE\\n  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def convertir_fecha(fecha_str):\n",
    "    # Divide la cadena en función del carácter \"|\"\n",
    "    partes = fecha_str.split(\"|\")\n",
    "\n",
    "    # Elimina los espacios en blanco y el salto de línea de cada parte y convierte a enteros\n",
    "    dia = int(partes[0].strip())\n",
    "    mes = int(partes[1].strip())\n",
    "    ano = int(partes[2].strip())\n",
    "\n",
    "    # Ajusta el valor del año para que sea \"1992\" en lugar de \"92\"\n",
    "    if ano >= 0 and ano <= 99:\n",
    "        ano += 1900\n",
    "\n",
    "    # Crea un objeto de fecha\n",
    "    return datetime(year=ano, month=mes, day=dia)\n",
    "\n",
    "\n",
    "df['Fecha_Nacimiento'] = [convertir_fecha(fecha) for fecha in df['Fecha_Nacimiento']]\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "00af1811-d1d0-4707-9bc4-ae0378b7a908",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nombre</th>\n",
       "      <th>Fecha_Nacimiento</th>\n",
       "      <th>Documento_id</th>\n",
       "      <th>Parentesco</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Angelica Vannessa Ramirez Rubio</td>\n",
       "      <td>1992-12-11</td>\n",
       "      <td>1072667399</td>\n",
       "      <td>ESPOS@</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>German Reina Bojaca</td>\n",
       "      <td>1959-03-11</td>\n",
       "      <td>2994376</td>\n",
       "      <td>SUEGR@O PADRE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Nombre Fecha_Nacimiento Documento_id  \\\n",
       "0  Angelica Vannessa Ramirez Rubio       1992-12-11   1072667399   \n",
       "1              German Reina Bojaca       1959-03-11      2994376   \n",
       "\n",
       "      Parentesco  \n",
       "0         ESPOS@  \n",
       "1  SUEGR@O PADRE  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Lista de cadenas con el patrón \" | \"\n",
    "lista = df['Nombre']\n",
    "\n",
    "# Define el patrón a eliminar\n",
    "patron = r'\\n'  # El espacio y las barras verticales deben escaparse con \"\\\"\n",
    "\n",
    "# Utiliza re.sub() para eliminar el patrón en cada cadena de la lista\n",
    "df['Nombre']= [re.sub(patron, '', cadena) for cadena in df['Nombre']]\n",
    "df['Documento_id']= [re.sub(patron, '', cadena) for cadena in df['Documento_id']]\n",
    "df['Parentesco']= [re.sub(patron, '', cadena) for cadena in df['Parentesco']]\n",
    "# Imprime la lista resultante\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51f43e41-401c-43ad-9017-462cc2937225",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-datasets in c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages (4.9.3)\n",
      "Requirement already satisfied: absl-py in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from tensorflow-datasets) (1.4.0)\n",
      "Requirement already satisfied: array-record in c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-datasets) (0.4.1)\n",
      "Requirement already satisfied: click in c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-datasets) (8.1.7)\n",
      "Requirement already satisfied: dm-tree in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from tensorflow-datasets) (0.1.8)\n",
      "Requirement already satisfied: etils[enp,epath,etree]>=0.9.0 in c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-datasets) (1.4.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from tensorflow-datasets) (1.24.3)\n",
      "Requirement already satisfied: promise in c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-datasets) (2.3)\n",
      "Requirement already satisfied: protobuf>=3.20 in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from tensorflow-datasets) (3.20.3)\n",
      "Requirement already satisfied: psutil in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from tensorflow-datasets) (5.9.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from tensorflow-datasets) (2.31.0)\n",
      "Requirement already satisfied: tensorflow-metadata in c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-datasets) (1.14.0)\n",
      "Requirement already satisfied: termcolor in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from tensorflow-datasets) (2.3.0)\n",
      "Requirement already satisfied: toml in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from tensorflow-datasets) (0.10.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from tensorflow-datasets) (4.66.1)\n",
      "Requirement already satisfied: wrapt in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from tensorflow-datasets) (1.15.0)\n",
      "Requirement already satisfied: importlib_resources in c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets) (6.0.1)\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets) (4.5.0)\n",
      "Requirement already satisfied: zipp in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets) (3.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from requests>=2.19.0->tensorflow-datasets) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from requests>=2.19.0->tensorflow-datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from requests>=2.19.0->tensorflow-datasets) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from requests>=2.19.0->tensorflow-datasets) (2023.7.22)\n",
      "Requirement already satisfied: colorama in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from click->tensorflow-datasets) (0.4.6)\n",
      "Requirement already satisfied: six in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from promise->tensorflow-datasets) (1.16.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-metadata->tensorflow-datasets) (1.60.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e32d48d0-c67d-4108-8c64-8bad609a6358",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-datasets in c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages (4.9.3)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: absl-py in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from tensorflow-datasets) (1.4.0)\n",
      "Requirement already satisfied: array-record in c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-datasets) (0.4.1)\n",
      "Requirement already satisfied: click in c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-datasets) (8.1.7)\n",
      "Requirement already satisfied: dm-tree in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from tensorflow-datasets) (0.1.8)\n",
      "Requirement already satisfied: etils[enp,epath,etree]>=0.9.0 in c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-datasets) (1.4.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from tensorflow-datasets) (1.24.3)\n",
      "Requirement already satisfied: promise in c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-datasets) (2.3)\n",
      "Requirement already satisfied: protobuf>=3.20 in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from tensorflow-datasets) (3.20.3)\n",
      "Requirement already satisfied: psutil in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from tensorflow-datasets) (5.9.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from tensorflow-datasets) (2.31.0)\n",
      "Requirement already satisfied: tensorflow-metadata in c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-datasets) (1.14.0)\n",
      "Requirement already satisfied: termcolor in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from tensorflow-datasets) (2.3.0)\n",
      "Requirement already satisfied: toml in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from tensorflow-datasets) (0.10.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from tensorflow-datasets) (4.66.1)\n",
      "Requirement already satisfied: wrapt in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from tensorflow-datasets) (1.15.0)\n",
      "Requirement already satisfied: importlib_resources in c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets) (6.0.1)\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets) (4.5.0)\n",
      "Requirement already satisfied: zipp in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets) (3.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from requests>=2.19.0->tensorflow-datasets) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from requests>=2.19.0->tensorflow-datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from requests>=2.19.0->tensorflow-datasets) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from requests>=2.19.0->tensorflow-datasets) (2023.7.22)\n",
      "Requirement already satisfied: colorama in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from click->tensorflow-datasets) (0.4.6)\n",
      "Requirement already satisfied: six in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from promise->tensorflow-datasets) (1.16.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-metadata->tensorflow-datasets) (1.60.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade tensorflow-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d41c230a-af3b-4591-a02d-4e9c0a1be56c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'core' from partially initialized module 'tensorflow_datasets' (most likely due to a circular import) (C:\\Users\\pc\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow_datasets\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m absolute_import, division, print_function, unicode_literals\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtfds\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow_datasets\\__init__.py:43\u001b[0m\n\u001b[0;32m     41\u001b[0m _TIMESTAMP_IMPORT_STARTS \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mabsl\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m logging\n\u001b[1;32m---> 43\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlogging\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_tfds_logging\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlogging\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m call_metadata \u001b[38;5;28;01mas\u001b[39;00m _call_metadata\n\u001b[0;32m     46\u001b[0m _metadata \u001b[38;5;241m=\u001b[39m _call_metadata\u001b[38;5;241m.\u001b[39mCallMetadata()\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'core' from partially initialized module 'tensorflow_datasets' (most likely due to a circular import) (C:\\Users\\pc\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow_datasets\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "logger = tf.get_logger()\n",
    "\n",
    "logger.setLevel(logging.ERROR)\n",
    "\n",
    "\n",
    "dataset, metadata = tfds.load('mnist', as_supervised=True, with_info=True)\n",
    "train_dataset, test_dataset = dataset['train'], dataset['test']\n",
    "\n",
    "class_names = [\n",
    "    'Cero', 'Uno', 'Dos', 'Tres', 'Cuatro', 'Cinco', 'Seis',\n",
    "    'Siete', 'Ocho', 'Nueve'\n",
    "]\n",
    "\n",
    "num_train_examples = metadata.splits['train'].num_examples\n",
    "num_test_examples = metadata.splits['test'].num_examples\n",
    "\n",
    "#Normalizar: Numeros de 0 a 255, que sean de 0 a 1\n",
    "def normalize(images, labels):\n",
    "    images = tf.cast(images, tf.float32)\n",
    "    images /= 255\n",
    "    return images, labels\n",
    "\n",
    "train_dataset = train_dataset.map(normalize)\n",
    "test_dataset = test_dataset.map(normalize)\n",
    "\n",
    "#Estructura de la red\n",
    "model = tf.keras.Sequential([\n",
    "\ttf.keras.layers.Flatten(input_shape=(28,28,1)),\n",
    "\ttf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "\ttf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "\ttf.keras.layers.Dense(10, activation=tf.nn.softmax) #para clasificacion\n",
    "])\n",
    "\n",
    "#Indicar las funciones a utilizar\n",
    "model.compile(\n",
    "\toptimizer='adam',\n",
    "\tloss='sparse_categorical_crossentropy',\n",
    "\tmetrics=['accuracy']\n",
    ")\n",
    "\n",
    "#Aprendizaje por lotes de 32 cada lote\n",
    "BATCHSIZE = 32\n",
    "train_dataset = train_dataset.repeat().shuffle(num_train_examples).batch(BATCHSIZE)\n",
    "test_dataset = test_dataset.batch(BATCHSIZE)\n",
    "\n",
    "#Realizar el aprendizaje\n",
    "model.fit(\n",
    "\ttrain_dataset, epochs=5,\n",
    "\tsteps_per_epoch=math.ceil(num_train_examples/BATCHSIZE) #No sera necesario pronto\n",
    ")\n",
    "\n",
    "#Evaluar nuestro modelo ya entrenado, contra el dataset de pruebas\n",
    "test_loss, test_accuracy = model.evaluate(\n",
    "\ttest_dataset, steps=math.ceil(num_test_examples/32)\n",
    ")\n",
    "\n",
    "print(\"Resultado en las pruebas: \", test_accuracy)\n",
    "\n",
    "\n",
    "for test_images, test_labels in test_dataset.take(1):\n",
    "\ttest_images = test_images.numpy()\n",
    "\ttest_labels = test_labels.numpy()\n",
    "\tpredictions = model.predict(test_images)\n",
    "\n",
    "def plot_image(i, predictions_array, true_labels, images):\n",
    "\tpredictions_array, true_label, img = predictions_array[i], true_labels[i], images[i]\n",
    "\tplt.grid(False)\n",
    "\tplt.xticks([])\n",
    "\tplt.yticks([])\n",
    "\n",
    "\tplt.imshow(img[...,0], cmap=plt.cm.binary)\n",
    "\n",
    "\tpredicted_label = np.argmax(predictions_array)\n",
    "\tif predicted_label == true_label:\n",
    "\t\tcolor = 'blue'\n",
    "\telse:\n",
    "\t\tcolor = 'red'\n",
    "\n",
    "\tplt.xlabel(\"Prediccion: {}\".format(class_names[predicted_label]), color=color)\n",
    "\n",
    "def plot_value_array(i, predictions_array, true_label):\n",
    "\tpredictions_array, true_label = predictions_array[i], true_label[i]\n",
    "\tplt.grid(False)\n",
    "\tplt.xticks([])\n",
    "\tplt.yticks([])\n",
    "\tthisplot = plt.bar(range(10), predictions_array, color=\"#888888\")\n",
    "\tplt.ylim([0,1])\n",
    "\tpredicted_label = np.argmax(predictions_array)\n",
    "\n",
    "\tthisplot[predicted_label].set_color('red')\n",
    "\tthisplot[true_label].set_color('blue')\n",
    "\n",
    "numrows=5\n",
    "numcols=3\n",
    "numimages = numrows*numcols\n",
    "\n",
    "plt.figure(figsize=(2*2*numcols, 2*numrows))\n",
    "for i in range(numimages):\n",
    "\tplt.subplot(numrows, 2*numcols, 2*i+1)\n",
    "\tplot_image(i, predictions, test_labels, test_images)\n",
    "\tplt.subplot(numrows, 2*numcols, 2*i+2)\n",
    "\tplot_value_array(i, predictions, test_labels)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "533bd473-33e2-4592-a02a-f976d5b2250d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'core' from partially initialized module 'tensorflow_datasets' (most likely due to a circular import) (C:\\Users\\pc\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow_datasets\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m absolute_import, division, print_function, unicode_literals\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtfds\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow_datasets\\__init__.py:43\u001b[0m\n\u001b[0;32m     41\u001b[0m _TIMESTAMP_IMPORT_STARTS \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mabsl\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m logging\n\u001b[1;32m---> 43\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlogging\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_tfds_logging\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlogging\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m call_metadata \u001b[38;5;28;01mas\u001b[39;00m _call_metadata\n\u001b[0;32m     46\u001b[0m _metadata \u001b[38;5;241m=\u001b[39m _call_metadata\u001b[38;5;241m.\u001b[39mCallMetadata()\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'core' from partially initialized module 'tensorflow_datasets' (most likely due to a circular import) (C:\\Users\\pc\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow_datasets\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "logger = tf.get_logger()\n",
    "logger.setLevel(logging.ERROR)\n",
    "\n",
    "# Cargar el conjunto de datos MNIST\n",
    "dataset, metadata = tfds.load('mnist', as_supervised=True, with_info=True)\n",
    "train_dataset, test_dataset = dataset['train'], dataset['test']\n",
    "\n",
    "class_names = [\n",
    "    'Cero', 'Uno', 'Dos', 'Tres', 'Cuatro', 'Cinco', 'Seis',\n",
    "    'Siete', 'Ocho', 'Nueve'\n",
    "]\n",
    "\n",
    "num_train_examples = metadata.splits['train'].num_examples\n",
    "num_test_examples = metadata.splits['test'].num_examples\n",
    "\n",
    "# Normalizar las imágenes\n",
    "def normalize(images, labels):\n",
    "    images = tf.cast(images, tf.float32)\n",
    "    images /= 255\n",
    "    return images, labels\n",
    "\n",
    "train_dataset = train_dataset.map(normalize)\n",
    "test_dataset = test_dataset.map(normalize)\n",
    "\n",
    "# Estructura de la red neuronal\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)  # para clasificación\n",
    "])\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Tamaño del lote para el entrenamiento\n",
    "BATCHSIZE = 32\n",
    "train_dataset = train_dataset.repeat().shuffle(num_train_examples).batch(BATCHSIZE)\n",
    "test_dataset = test_dataset.batch(BATCHSIZE)\n",
    "\n",
    "# Entrenar el modelo\n",
    "model.fit(\n",
    "    train_dataset, epochs=5,\n",
    "    steps_per_epoch=math.ceil(num_train_examples / BATCHSIZE)\n",
    ")\n",
    "\n",
    "# Evaluar el modelo en el conjunto de prueba\n",
    "test_loss, test_accuracy = model.evaluate(\n",
    "    test_dataset, steps=math.ceil(num_test_examples / 32)\n",
    ")\n",
    "\n",
    "print(\"Precisión en las pruebas: \", test_accuracy)\n",
    "\n",
    "# Realizar predicciones en un lote de imágenes\n",
    "for test_images, test_labels in test_dataset.take(1):\n",
    "    test_images = test_images.numpy()\n",
    "    test_labels = test_labels.numpy()\n",
    "    predictions = model.predict(test_images)\n",
    "\n",
    "# Funciones para graficar imágenes y resultados\n",
    "def plot_image(i, predictions_array, true_labels, images):\n",
    "    predictions_array, true_label, img = predictions_array[i], true_labels[i], images[i]\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    plt.imshow(img[..., 0], cmap=plt.cm.binary)\n",
    "\n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "    if predicted_label == true_label:\n",
    "        color = 'blue'\n",
    "    else:\n",
    "        color = 'red'\n",
    "\n",
    "    plt.xlabel(\"Predicción: {}\".format(class_names[predicted_label]), color=color)\n",
    "\n",
    "def plot_value_array(i, predictions_array, true_label):\n",
    "    predictions_array, true_label = predictions_array[i], true_label[i]\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    thisplot = plt.bar(range(10), predictions_array, color=\"#888888\")\n",
    "    plt.ylim([0, 1])\n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "\n",
    "    thisplot[predicted_label].set_color('red')\n",
    "    thisplot[true_label].set_color('blue')\n",
    "\n",
    "numrows = 5\n",
    "numcols = 3\n",
    "numimages = numrows * numcols\n",
    "\n",
    "plt.figure(figsize=(2 * 2 * numcols, 2 * numrows))\n",
    "for i in range(numimages):\n",
    "    plt.subplot(numrows, 2 * numcols, 2 * i + 1)\n",
    "    plot_image(i, predictions, test_labels, test_images)\n",
    "    plt.subplot(numrows, 2 * numcols, 2 * i + 2)\n",
    "    plot_value_array(i, predictions, test_labels)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d887e10b-ea1c-4a1c-8589-78679263363c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-datasets in c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages (4.9.3)\n",
      "Requirement already satisfied: absl-py in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from tensorflow-datasets) (1.4.0)\n",
      "Requirement already satisfied: array-record in c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-datasets) (0.4.1)\n",
      "Requirement already satisfied: click in c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-datasets) (8.1.7)\n",
      "Requirement already satisfied: dm-tree in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from tensorflow-datasets) (0.1.8)\n",
      "Requirement already satisfied: etils[enp,epath,etree]>=0.9.0 in c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-datasets) (1.4.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from tensorflow-datasets) (1.24.3)\n",
      "Requirement already satisfied: promise in c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-datasets) (2.3)\n",
      "Requirement already satisfied: protobuf>=3.20 in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from tensorflow-datasets) (3.20.3)\n",
      "Requirement already satisfied: psutil in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from tensorflow-datasets) (5.9.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from tensorflow-datasets) (2.31.0)\n",
      "Requirement already satisfied: tensorflow-metadata in c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-datasets) (1.14.0)\n",
      "Requirement already satisfied: termcolor in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from tensorflow-datasets) (2.3.0)\n",
      "Requirement already satisfied: toml in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from tensorflow-datasets) (0.10.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from tensorflow-datasets) (4.66.1)\n",
      "Requirement already satisfied: wrapt in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from tensorflow-datasets) (1.15.0)\n",
      "Requirement already satisfied: importlib_resources in c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets) (6.0.1)\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets) (4.5.0)\n",
      "Requirement already satisfied: zipp in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets) (3.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from requests>=2.19.0->tensorflow-datasets) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from requests>=2.19.0->tensorflow-datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from requests>=2.19.0->tensorflow-datasets) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from requests>=2.19.0->tensorflow-datasets) (2023.7.22)\n",
      "Requirement already satisfied: colorama in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from click->tensorflow-datasets) (0.4.6)\n",
      "Requirement already satisfied: six in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from promise->tensorflow-datasets) (1.16.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-metadata->tensorflow-datasets) (1.60.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade tensorflow-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a6c3939-1e2b-4f47-9bfd-fd92e32fe1c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (2.13.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: tensorflow-intel==2.13.0 in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.9.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.24.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.20.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (4.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.15.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.58.0)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.13.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.4.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.3.7)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: urllib3<2.0 in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (6.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.2.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\pc\\anaconda3\\envs\\proyecto_ocr\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade tensorflow"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
